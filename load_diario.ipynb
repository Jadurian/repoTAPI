{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import pyodbc\n",
    "import requests\n",
    "import io\n",
    "from datetime import datetime, timedelta\n",
    "import sqlalchemy\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#funciones\n",
    "\n",
    "def iterar_entre_fechas(fecha_desde, fecha_hasta):\n",
    "    fecha_actual = datetime.strptime(fecha_desde, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "    fecha_fin = datetime.strptime(fecha_hasta, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "\n",
    "    # Asegurarse de que fecha_actual sea exactamente a la medianoche\n",
    "    fecha_actual = fecha_actual.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "    while fecha_actual <= fecha_fin:\n",
    "        fecha_siguiente = fecha_actual + timedelta(hours=23, minutes=59)\n",
    "        yield fecha_actual, fecha_siguiente\n",
    "        # Añadir un día para la próxima iteración\n",
    "        fecha_actual += timedelta(days=1)\n",
    "        \n",
    "#Con este script se puede obtener la fecha del último documento cargado por CAMMESA\n",
    "def  ultimo_dia_CAMM():\n",
    "\n",
    "    ultimafecha = requests.get(\"https://api.cammesa.com/pub-svc/public/obtieneFechaUltimoDocumento?nemo=PARTE_POST_OPERATIVO\")\n",
    "\n",
    "    fecha = ultimafecha.text[10:-2]\n",
    "\n",
    "    return fecha\n",
    "\n",
    "def ultimo_dia_bd():\n",
    "    server = 'DARCCVWSQL19'\n",
    "    database = 'TAPI'\n",
    "    tabla = 'Valores_Gen_Diario_Automatico'\n",
    "\n",
    "    connection_string = f'DRIVER=ODBC Driver 17 for SQL Server;SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "\n",
    "    # Conectar a la base de datos\n",
    "    connection = pyodbc.connect(connection_string)\n",
    "\n",
    "    # Crear un cursor para ejecutar consultas\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # TODO: Crear acá la tabla en la BBDD\n",
    "    #  Consulta SQL\n",
    "    query = f\"SELECT TOP 1 FECHA FROM {tabla} ORDER BY FECHA DESC\"\n",
    "\n",
    "    # Ejecutar la consulta\n",
    "    df = pd.read_sql(query, connection)\n",
    "\n",
    "    # Cerrar el cursor\n",
    "    cursor.close()\n",
    "\n",
    "    ultimo_dia = df['FECHA'][0]\n",
    "    \n",
    "    return ultimo_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ultimo_dia_bd())\n",
    "print(ultimo_dia_CAMM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS DE LA BBDD, SERVER Y TABLA\n",
    "\n",
    "server = 'DARCCVWSQL19'\n",
    "database = 'TAPI'\n",
    "\n",
    "#1\n",
    "#-------------------------------------------------------#\n",
    "tabla_valores = 'Valores_Gen_Corregidos'\n",
    "tabla_contratos = 'Contratos_Corregidos'\n",
    "tabla_novedades = 'NOVEDADES_Corregidos'\n",
    "\n",
    "#-------------------------------------------------------#\n",
    "\n",
    "#2\n",
    "#-------------------------------------------------------#\n",
    "# Fechas para seleccionar el día de la carga se debe iterar\n",
    "\n",
    "fecha_desde_obj = datetime.fromisoformat(ultimo_dia_bd())\n",
    "\n",
    "fecha_hasta_obj = datetime.fromisoformat(ultimo_dia_CAMM())\n",
    "\n",
    "fecha_desde_bd = ultimo_dia_bd() #OJO DE QUE TABLA TOMA EL ULTIMO DIA\n",
    "\n",
    "fecha_datetime = datetime.strptime(fecha_desde_bd, \"%Y-%m-%d\")\n",
    "\n",
    "fecha_siguiente = fecha_datetime + timedelta(days=1) #Sumar un día\n",
    "\n",
    "fecha_desde = fecha_siguiente.strftime(\"%Y-%m-%d\") #Convertir de nuevo a string si es necesario\n",
    "\n",
    "fecha_hasta = ultimo_dia_CAMM() #ultimo informe en API CAMMESA\n",
    "\n",
    "fecha_desde = fecha_desde+\"T00:00:00.000-03:00\" \n",
    "fecha_hasta = fecha_hasta+\"T23:59:00.000-03:00\"\n",
    "\n",
    "# fecha_desde_datetime = datetime.strptime(fecha_desde)\n",
    "# fecha_hasta_datetime = datetime.strptime(fecha_hasta)\n",
    "\n",
    "#fecha_desde = \"2024-04-20T00:00:00.000-03:00\"\n",
    "#fecha_hasta = \"2024-04-30T23:59:59.000-03:00\"\n",
    "\n",
    "#Defino la tabla de CAMMESA que me voy a traer\n",
    "\n",
    "NEMO = \"PARTE_POST_OPERATIVO_UNIF\"\n",
    "#NEMO = \"PARTE_POST_OPERATIVO\"\n",
    "#-------------------------------------------------------#\n",
    "\n",
    "#URL para capturar Id del documento y el zip file:\n",
    "\n",
    "#Busco los zip disponibles para traer así puedo extraer el id\n",
    "URL = f\"https://api.cammesa.com/pub-svc/public/\"\n",
    "\n",
    "method_id = \"findDocumentosByNemoRango?\" #ID\n",
    "method_zip = \"findAllAttachmentZipByNemoId?\" #metodo\n",
    "\n",
    "\n",
    "zip_path = r\"C:\\Users\\jadurian\\Documents\\Tapi\\.zips\"\n",
    "mdb_path = r\"C:\\Users\\jadurian\\Documents\\Tapi\\.zips\\.mdb\"\n",
    "\n",
    "connection_string = f'DRIVER=ODBC Driver 17 for SQL Server;SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "\n",
    "# Establecer la conexión con la base de datos de SQL Server\n",
    "conn = pyodbc.connect(connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#url_doc_id = f\"{URL}{method_id}fechadesde={fecha_desde}&fechahasta={fecha_hasta}&nemo={NEMO}\"\n",
    "\n",
    "dataframes = []\n",
    "dfout = pd.DataFrame()\n",
    "dfout2 = pd.DataFrame()\n",
    "df_filtrado = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_desde = \"2023-01-01T00:00:00.000-03:00\"\n",
    "fecha_hasta = \"2023-06-30T23:59:59.000-03:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fecha_desde_obj < fecha_hasta_obj:\n",
    "    print(\"Se realiza el update\")\n",
    "\n",
    "    for fecha_actual, fecha_siguiente in iterar_entre_fechas(fecha_desde, fecha_hasta):\n",
    "\n",
    "        valores_generadores = pd.DataFrame()\n",
    "        contrato_abastecimiento = pd.DataFrame()\n",
    "\n",
    "        url_doc_id = f\"{URL}{method_id}fechadesde={fecha_actual.isoformat()}&fechahasta={fecha_siguiente.isoformat()}&nemo={NEMO}\"\n",
    "        \n",
    "        #obtener el doc_id del dia actual (corregido)\n",
    "        dia_mdb = fecha_actual.strftime(\"%d-%m-%Y\")\n",
    "        try:\n",
    "            with requests.get(url_doc_id) as response:\n",
    "                if response.status_code == 200:\n",
    "                    PPO=response.json()\n",
    "                    doc_id = PPO[-1]['id']\n",
    "                    print(dia_mdb)\n",
    "                else:\n",
    "                    print(\"La solicitud falló con el código de estado:\", response.status_code)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Manejar la excepción\n",
    "            print(\"Error al realizar la solicitud:\", e)\n",
    "\n",
    "        url_zip = f\"{URL}{method_zip}docId={doc_id}&nemo={NEMO}\"\n",
    "\n",
    "        #descargar el .zip del doc_id (corregido)\n",
    "\n",
    "        try:\n",
    "            with requests.get(url_doc_id) as response:\n",
    "                if response.status_code == 200:\n",
    "                    r = requests.get(url_zip)\n",
    "\n",
    "                    # Crear un objeto ZipFile a partir del contenido descargado\n",
    "                    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "                    # Directorio de destino para extraer los archivos ZIP\n",
    "                    destination_directory = \".zips\"\n",
    "\n",
    "                    # Extraer todos los archivos del ZIP en el directorio específico\n",
    "                    z.extractall(destination_directory)\n",
    "                    zip_name = z.namelist()[0]\n",
    "                else:\n",
    "                    print(\"La solicitud falló con el código de estado:\", response.status_code)\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Manejar la excepción\n",
    "            print(\"Error al realizar la solicitud:\", e)\n",
    "        \n",
    "        #Colocar los PATHs correctos donde se traeran los archivos\n",
    "        \n",
    "        path_zip_dia = f\"{zip_path}\\{zip_name}\"\n",
    "\n",
    "        #display(path_zip_dia)\n",
    "\n",
    "        \n",
    "        try:\n",
    "            # Extrae el archivo MDB de cada archivo ZIP diario\n",
    "            with zipfile.ZipFile(path_zip_dia, 'r') as zip_ref:\n",
    "                # Encontrar el nombre del archivo MDB dentro del ZIP diario\n",
    "                archivo_mdb = os.path.splitext(zip_name)[0] + \".mdb\"\n",
    "                zip_ref.extract(archivo_mdb, path=mdb_path)\n",
    "\n",
    "    \n",
    "            # Lee el archivo MDB y cargar la tabla VALORES_GENERADORES en un dataframe\n",
    "            mdb_file = os.path.join(mdb_path, archivo_mdb)\n",
    "            conn_str = f\"Driver={{Microsoft Access Driver (*.mdb, *.accdb)}};DBQ={mdb_file};\"\n",
    "            conn = pyodbc.connect(conn_str)\n",
    "\n",
    "            #3\n",
    "            #-------------------------------------------------------#\n",
    "            valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n",
    "            contrato_abastecimiento = pd.read_sql(\"SELECT * FROM CONTRATO_ABASTECIMIENTO\", conn)\n",
    "            novedades = pd.read_sql(\"SELECT * FROM NOVEDADES\", conn)\n",
    "            #-------------------------------------------------------#\n",
    "            conn.close()\n",
    "            \n",
    "            # Convertir dia_mdb a un objeto datetime\n",
    "            dia_datetime = datetime.strptime(dia_mdb, '%d-%m-%Y')\n",
    "\n",
    "            # Formatear la fecha en el formato YYYY-MM-DD como una cadena\n",
    "            dia_mdb_formatted = dia_datetime.strftime('%Y-%m-%d')\n",
    "\n",
    "            # Insertar la fecha formateada en la lista valores_generadores\n",
    "            \n",
    "            #4\n",
    "            #-------------------------------------------------------#\n",
    "            valores_generadores.insert(0, 'FECHA', dia_mdb_formatted)\n",
    "\n",
    "            contrato_abastecimiento.insert(0, 'FECHA', dia_mdb_formatted)\n",
    "\n",
    "            novedades.insert(0, 'FECHA', dia_mdb_formatted)\n",
    "            #-------------------------------------------------------#\n",
    "            quoted = urllib.parse.quote_plus(connection_string)\n",
    "\n",
    "            #Por limitaciones de tamaño de excel filtramos solo las máquinas Pampa\n",
    "            valores_filtrados = [\"ADTOHI\", \"AR21EO\", \"BAHIEO\", \"BBLATV29\", \"BBLATV30\",\n",
    "                                \"BBLMDI01\", \"BBLMDI02\", \"BBLMDI03\", \"BBLMDI04\", \n",
    "                                \"BBLMDI05\", \"BBLMDI06\", \"CERITV01\", \"CORTEO\", \n",
    "                                \"EBARTG01\", \"EBARTG02\", \"EBARTV01\", \"ETIGHI\", \n",
    "                                \"GEBATG01\", \"GEBATG02\", \"GEBATG03\", \"GEBATG04\", \n",
    "                                \"GEBATV01\", \"GEBATV02\", \"GUEMTG01\", \"GUEMTV11\", \n",
    "                                \"GUEMTV12\", \"GUEMTV13\", \"LDLATG01\", \"LDLATG02\", \n",
    "                                \"LDLATG03\", \"LDLATG04\", \"LDLATG05\", \"LDLATV01\", \n",
    "                                \"LDLMDI01\", \"LREYHB\", \"NIH1HI\", \"NIH2HI\", \"NIH3HI\", \n",
    "                                \"PAMEEO\",\"PE32EO\", \"PEP3EO\", \"PILBDI01\", \"PILBDI02\", \n",
    "                                \"PILBDI03\", \"PILBDI04\", \"PILBDI05\", \"PILBDI06\", \"PIQIDI01\", \"PPLEHI\"]\n",
    "            \n",
    "            contratos_filtrados = [\"C.T. LOMA DE LA LATA\", \"C.T.E.BARRAGAN TV-M\", \"CT LOMA II LA LATA-M\", \"GENELBA CC -MERCA\", \"PIEDRABUENA  R21-\",\"CT PILAR BS AS M\"]\n",
    "\n",
    "            # Filtrar el DataFrame por los valores especificados en la columna \"GRUPO\"\n",
    "\n",
    "            #DEFINIR EL DF A SUBIR\n",
    "\n",
    "            #5\n",
    "            #-------------------------------------------------------#\n",
    "\n",
    "            df_valores = valores_generadores[valores_generadores[\"GRUPO\"].isin(valores_filtrados)]  \n",
    "            \n",
    "            df_contratos = contrato_abastecimiento[contrato_abastecimiento[\"CONTRATO\"].isin(contratos_filtrados)]\n",
    "\n",
    "            df_novedades = novedades[novedades[\"GRUPO\"].isin(valores_filtrados)]\n",
    "\n",
    "            #-------------------------------------------------------#\n",
    "\n",
    "            #TODO: Revisar el filtrado previo a igresar la data    \n",
    "            \n",
    "            #df_filtrado = df_filtrado.sort_values(by=['FECHA', 'HORA', 'GRUPO'])\n",
    "\n",
    "            engine = sqlalchemy.create_engine('mssql+pyodbc:///?odbc_connect={}'.format(quoted))\n",
    "        \n",
    "            #ACÁ ESCRIBE LA DATA, REVISAR SIEMPRE ARGUMENTOS\n",
    "\n",
    "            #6\n",
    "            #-------------------------------------------------------#\n",
    "\n",
    "            df_valores.to_sql(f'{tabla_valores}', schema='dbo', con=engine, if_exists='append', chunksize=20000)\n",
    "\n",
    "            df_contratos.to_sql(f'{tabla_contratos}', schema='dbo', con=engine, if_exists='append', chunksize=20000)\n",
    "\n",
    "            df_novedades.to_sql(f'{tabla_novedades}', schema='dbo', con=engine, if_exists='append', chunksize=20000)\n",
    "\n",
    "            #dfout = pd.concat([dfout,df_valores], ignore_index=True)\n",
    "            #dfout2 = pd.concat([dfout2, df_contratos], ignore_index=True)\n",
    "\n",
    "            #-------------------------------------------------------#\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"El archivo {zip_name} no se encontró. Saltando al siguiente archivo...\")\n",
    "\n",
    "else:\n",
    "    print(f\"Última fecha en BD:{fecha_desde_obj} es igual a la última fecha del informe de CAMMESA: {fecha_hasta_obj}\\nNo se realiza el update\")\n",
    "\n",
    "#dfout.to_sql(f'{tabla_valores}', schema='dbo', con=engine, if_exists=\"replace\", chunksize=20000)\n",
    "#dfout2.to_sql(f'{tabla_contratos}', schema='dbo', con=engine, if_exists=\"replace\", chunksize=20000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvPampa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
