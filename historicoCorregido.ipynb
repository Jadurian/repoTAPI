{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"fecha\":\"2024-04-25\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import pyodbc\n",
    "import requests\n",
    "import io\n",
    "from datetime import datetime, timedelta\n",
    "import sqlalchemy\n",
    "import urllib\n",
    "\n",
    "from TAPI import capturar_fecha\n",
    "\n",
    "#funciones\n",
    "\n",
    "def iterar_entre_fechas(fecha_desde, fecha_hasta):\n",
    "    fecha_actual = datetime.strptime(fecha_desde, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "    fecha_fin = datetime.strptime(fecha_hasta, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "\n",
    "    # Asegurarse de que fecha_actual sea exactamente a la medianoche\n",
    "    fecha_actual = fecha_actual.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "    while fecha_actual <= fecha_fin:\n",
    "        fecha_siguiente = fecha_actual + timedelta(hours=23, minutes=59)\n",
    "        yield fecha_actual, fecha_siguiente\n",
    "        # Añadir un día para la próxima iteración\n",
    "        fecha_actual += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_desde = \"2023-03-01T00:00:00.000-03:00\"\n",
    "fecha_hasta = \"2023-03-31T23:59:59.000-03:00\"\n",
    "\n",
    "for fecha_actual, fecha_siguiente in iterar_entre_fechas(fecha_desde, fecha_hasta):\n",
    "    dia_mdb = fecha_actual.strftime(\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01255BEF763F7DD003258951005A1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_23884\\195633235.py:107: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942AA61382F54C3003258951005A7DC5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_23884\\195633235.py:107: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65A52C294183E45903258951005A8D9D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_23884\\195633235.py:107: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516E0B903AF161D303258951005AB244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_23884\\195633235.py:107: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A3D365F0951BD65C03258951006135E2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_23884\\195633235.py:107: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B225F5D8A886E70C0325895100617177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_23884\\195633235.py:107: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    }
   ],
   "source": [
    "# DATOS DE LA BBDD, SERVER Y TABLA\n",
    "\n",
    "#server = 'DESKTOP-37ESKFT\\SQLEXPRESS'\n",
    "server = 'DARCCVWSQL19'\n",
    "database = 'TAPI'\n",
    "\n",
    "\n",
    "#tabla = 'DiarioTest'\n",
    "tabla = \"Hist_Bk\"\n",
    "\n",
    "\n",
    "# Fechas para seleccionar el día de la carga se debe iterar\n",
    "\n",
    "fecha_desde = \"2023-01-01T00:00:00.000-03:00\"\n",
    "fecha_hasta = \"2023-01-06T23:59:59.000-03:00\"\n",
    "\n",
    "#URL para capturar Id del documento y el zip file:\n",
    "\n",
    "#Defino la tabla de CAMMESA que me voy a traer\n",
    "NEMO = \"PARTE_POST_OPERATIVO_UNIF\"\n",
    "#NEMO = \"PARTE_POST_OPERATIVO\"\n",
    "\n",
    "#Busco los zip disponibles para traer así puedo extraer el id\n",
    "URL = f\"https://api.cammesa.com/pub-svc/public/\"\n",
    "\n",
    "method_id = \"findDocumentosByNemoRango?\" #ID\n",
    "method_zip = \"findAllAttachmentZipByNemoId?\"\n",
    "\n",
    "\n",
    "zip_path = r\"C:\\Users\\jadurian\\Documents\\Tapi\\.zips\"\n",
    "mdb_path = r\"C:\\Users\\jadurian\\Documents\\Tapi\\.zips\\.mdb\"\n",
    "\n",
    "connection_string = f'DRIVER=ODBC Driver 17 for SQL Server;SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "\n",
    "# Establecer la conexión con la base de datos de SQL Server\n",
    "conn = pyodbc.connect(connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#url_doc_id = f\"{URL}{method_id}fechadesde={fecha_desde}&fechahasta={fecha_hasta}&nemo={NEMO}\"\n",
    "\n",
    "dataframes = []\n",
    "dfout = pd.DataFrame()\n",
    "df_filtrado = pd.DataFrame()\n",
    "\n",
    "for fecha_actual, fecha_siguiente in iterar_entre_fechas(fecha_desde, fecha_hasta):\n",
    "    valores_generadores = pd.DataFrame()\n",
    "    url_doc_id = f\"{URL}{method_id}fechadesde={fecha_actual.isoformat()}&fechahasta={fecha_siguiente.isoformat()}&nemo={NEMO}\"\n",
    "    \n",
    "    #obtener el doc_id del dia actual (corregido)\n",
    "    dia_mdb = fecha_actual.strftime(\"%d-%m-%Y\")\n",
    "    try:\n",
    "        with requests.get(url_doc_id) as response:\n",
    "            if response.status_code == 200:\n",
    "                PPO=response.json()\n",
    "                doc_id = PPO[-1]['id']\n",
    "                print(doc_id)\n",
    "            else:\n",
    "                print(\"La solicitud falló con el código de estado:\", response.status_code)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Manejar la excepción\n",
    "        print(\"Error al realizar la solicitud:\", e)\n",
    "\n",
    "    url_zip = f\"{URL}{method_zip}docId={doc_id}&nemo={NEMO}\"\n",
    "\n",
    "    #descargar el .zip del doc_id (corregido)\n",
    "\n",
    "    try:\n",
    "        with requests.get(url_doc_id) as response:\n",
    "            if response.status_code == 200:\n",
    "                r = requests.get(url_zip)\n",
    "\n",
    "                # Crear un objeto ZipFile a partir del contenido descargado\n",
    "                z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "                # Directorio de destino para extraer los archivos ZIP\n",
    "                destination_directory = \".zips\"\n",
    "\n",
    "                # Extraer todos los archivos del ZIP en el directorio específico\n",
    "                z.extractall(destination_directory)\n",
    "                zip_name = z.namelist()[0]\n",
    "            else:\n",
    "                print(\"La solicitud falló con el código de estado:\", response.status_code)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Manejar la excepción\n",
    "        print(\"Error al realizar la solicitud:\", e)\n",
    "    \n",
    "    #Colocar los PATHs correctos donde se traeran los archivos\n",
    "    \n",
    "    path_zip_dia = f\"{zip_path}\\{zip_name}\"\n",
    "\n",
    "    #display(path_zip_dia)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        # Extrae el archivo MDB de cada archivo ZIP diario\n",
    "        with zipfile.ZipFile(path_zip_dia, 'r') as zip_ref:\n",
    "            # Encontrar el nombre del archivo MDB dentro del ZIP diario\n",
    "            archivo_mdb = os.path.splitext(zip_name)[0] + \".mdb\"\n",
    "            zip_ref.extract(archivo_mdb, path=mdb_path)\n",
    "\n",
    "   \n",
    "        # Lee el archivo MDB y cargar la tabla VALORES_GENERADORES en un dataframe\n",
    "        mdb_file = os.path.join(mdb_path, archivo_mdb)\n",
    "        conn_str = f\"Driver={{Microsoft Access Driver (*.mdb, *.accdb)}};DBQ={mdb_file};\"\n",
    "        conn = pyodbc.connect(conn_str)\n",
    "        valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n",
    "        conn.close()\n",
    "\n",
    "        # Convertir dia_mdb a un objeto datetime\n",
    "        dia_datetime = datetime.strptime(dia_mdb, '%d-%m-%Y')\n",
    "\n",
    "        # Formatear la fecha en el formato YYYY-MM-DD como una cadena\n",
    "        dia_mdb_formatted = dia_datetime.strftime('%Y-%m-%d')\n",
    "\n",
    "        # Insertar la fecha formateada en la lista valores_generadores\n",
    "        valores_generadores.insert(0, 'FECHA', dia_mdb_formatted)\n",
    "\n",
    "        quoted = urllib.parse.quote_plus(connection_string)\n",
    "\n",
    "        #Por limitaciones de tamaño de excel filtramos solo las máquinas Pampa\n",
    "        valores_filtrados = [\"ADTOHI\", \"AR21EO\", \"BAHIEO\", \"BBLATV29\", \"BBLATV30\",\n",
    "                            \"BBLMDI01\", \"BBLMDI02\", \"BBLMDI03\", \"BBLMDI04\", \n",
    "                            \"BBLMDI05\", \"BBLMDI06\", \"CERITV01\", \"CORTEO\", \n",
    "                            \"EBARTG01\", \"EBARTG02\", \"EBARTV01\", \"ETIGHI\", \n",
    "                            \"GEBATG01\", \"GEBATG02\", \"GEBATG03\", \"GEBATG04\", \n",
    "                            \"GEBATV01\", \"GEBATV02\", \"GUEMTG01\", \"GUEMTV11\", \n",
    "                            \"GUEMTV12\", \"GUEMTV13\", \"LDLATG01\", \"LDLATG02\", \n",
    "                            \"LDLATG03\", \"LDLATG04\", \"LDLATG05\", \"LDLATV01\", \n",
    "                            \"LDLMDI01\", \"LREYHB\", \"NIH1HI\", \"NIH2HI\", \"NIH3HI\", \n",
    "                            \"PAMEEO\", \"PEP3EO\", \"PILBDI01\", \"PILBDI02\", \n",
    "                            \"PILBDI03\", \"PILBDI04\", \"PILBDI05\", \"PILBDI06\", \"PIQIDI01\", \"PPLEHI\"]\n",
    "\n",
    "        # Filtrar el DataFrame por los valores especificados en la columna \"GRUPO\"\n",
    "        df_filtrado = valores_generadores[valores_generadores['GRUPO'].isin(valores_filtrados)]   \n",
    "        # display(df_filtrado)\n",
    "        # print(len(df_filtrado.columns))\n",
    "        # break\n",
    "        #TODO: Revisar el filtrado previo a igresar la data    \n",
    "        \n",
    "        #df_filtrado = df_filtrado.sort_values(by=['FECHA', 'HORA', 'GRUPO'])\n",
    "\n",
    "        engine = sqlalchemy.create_engine('mssql+pyodbc:///?odbc_connect={}'.format(quoted))\n",
    "\n",
    "    \n",
    "        #ACÁ ESCRIBE LA DATA, REVISAR SIEMPRE ARGUMENTOS\n",
    "        #df_filtrado.to_sql(f'{tabla}', schema='dbo', con=engine, if_exists='append', chunksize=20000)\n",
    "        \n",
    "        dfout = pd.concat([dfout,df_filtrado], ignore_index=True)\n",
    "\n",
    "        dfout.to_sql(f'{tabla}', schema='dbo', con=engine, if_exists=\"replace\", chunksize=20000)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"El archivo {zip_name} no se encontró. Saltando al siguiente archivo...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15984 entries, 0 to 15983\n",
      "Data columns (total 40 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   FECHA                15984 non-null  object \n",
      " 1   GRUPO                15984 non-null  object \n",
      " 2   HORA                 15984 non-null  int64  \n",
      " 3   ARL                  15984 non-null  int64  \n",
      " 4   ESTADO_OPE           15984 non-null  object \n",
      " 5   PI_SOTR              15984 non-null  float64\n",
      " 6   ARL_ECON             15984 non-null  int64  \n",
      " 7   EST_REMUN            15984 non-null  object \n",
      " 8   ENERGIA              15984 non-null  float64\n",
      " 9   PRECIO_NODO          15984 non-null  float64\n",
      " 10  PR_REM_ENERGIA       9806 non-null   float64\n",
      " 11  SMEC                 15984 non-null  object \n",
      " 12  POT_DISP             15984 non-null  float64\n",
      " 13  POT_OPE_CPO          13536 non-null  float64\n",
      " 14  COMPRA_SPOT          15168 non-null  float64\n",
      " 15  SCTD                 9249 non-null   float64\n",
      " 16  SCO                  8601 non-null   float64\n",
      " 17  PIND                 13536 non-null  float64\n",
      " 18  PINDPROG             13536 non-null  float64\n",
      " 19  PINDFORZ             13536 non-null  float64\n",
      " 20  POT_DISP_GAS         15984 non-null  float64\n",
      " 21  POT_DISP_RESERVA     0 non-null      object \n",
      " 22  GAS_NOMINADO         0 non-null      object \n",
      " 23  COSTO_406            15984 non-null  float64\n",
      " 24  REM_ADICIONAL        15984 non-null  float64\n",
      " 25  DESP_ECON            15984 non-null  object \n",
      " 26  CCM                  120 non-null    float64\n",
      " 27  CFO                  992 non-null    float64\n",
      " 28  CGN                  4394 non-null   float64\n",
      " 29  CGO                  3911 non-null   float64\n",
      " 30  POT_DISP_R19         13512 non-null  float64\n",
      " 31  FACTOR_KM            13512 non-null  float64\n",
      " 32  HORA_REPRESENTATIVA  4106 non-null   object \n",
      " 33  ENERG_GEN_TRANSAC    228 non-null    float64\n",
      " 34  ENERG_OPE_TRANSAC    228 non-null    float64\n",
      " 35  SOBREC_FORZ_PROPIO   0 non-null      object \n",
      " 36  PGENE_RES354         264 non-null    float64\n",
      " 37  CGU_PROPIO           264 non-null    float64\n",
      " 38  CGU_MEM              264 non-null    float64\n",
      " 39  CGU_GAS_CEDIDO       264 non-null    float64\n",
      "dtypes: float64(27), int64(3), object(10)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "valores_generadores.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quoted = urllib.parse.quote_plus(connection_string)\n",
    "engine = sqlalchemy.create_engine('mssql+pyodbc:///?odbc_connect={}'.format(quoted))\n",
    "dfout.to_sql('DiarioTest', schema='dbo', con=engine, if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvPampa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
