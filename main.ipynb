{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import pyodbc\n",
    "import requests\n",
    "import io\n",
    "from datetime import datetime, timedelta\n",
    "import sqlalchemy\n",
    "import urllib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#funciones\n",
    "\n",
    "def iterar_entre_fechas(fecha_desde, fecha_hasta):\n",
    "    fecha_actual = datetime.strptime(fecha_desde, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "    fecha_fin = datetime.strptime(fecha_hasta, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "\n",
    "    # Asegurarse de que fecha_actual sea exactamente a la medianoche\n",
    "    fecha_actual = fecha_actual.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "    while fecha_actual <= fecha_fin:\n",
    "        fecha_siguiente = fecha_actual + timedelta(hours=23, minutes=59)\n",
    "        yield fecha_actual, fecha_siguiente\n",
    "        # Añadir un día para la próxima iteración\n",
    "        fecha_actual += timedelta(days=1)\n",
    "        \n",
    "#Con este script se puede obtener la fecha del último documento cargado por CAMMESA\n",
    "def  ultimo_dia_CAMM(nemo:str):\n",
    "\n",
    "    ultimafecha = requests.get(f\"https://api.cammesa.com/pub-svc/public/obtieneFechaUltimoDocumento?nemo={nemo}\")\n",
    "\n",
    "    fecha = ultimafecha.text[10:-2]\n",
    "\n",
    "    return fecha\n",
    "\n",
    "def ultimo_dia(tabla:str):\n",
    "    server = 'DARCCVWSQL19'\n",
    "    database = 'TAPI'\n",
    "    tabla = tabla\n",
    "\n",
    "    connection_string = f'DRIVER=ODBC Driver 17 for SQL Server;SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "\n",
    "    # Conectar a la base de datos\n",
    "    connection = pyodbc.connect(connection_string)\n",
    "\n",
    "    # Crear un cursor para ejecutar consultas\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # TODO: Crear acá la tabla en la BBDD\n",
    "    #  Consulta SQL\n",
    "    query = f\"SELECT TOP 1 FECHA FROM {tabla} ORDER BY FECHA DESC\"\n",
    "\n",
    "    # Ejecutar la consulta\n",
    "    df = pd.read_sql(query, connection)\n",
    "\n",
    "    # Cerrar el cursor\n",
    "    cursor.close()\n",
    "\n",
    "    ultimo_dia = df['FECHA'][0]\n",
    "    \n",
    "    return ultimo_dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function es_ultimo_dia_del_mes at 0x0000019A57B7C540>\n",
      "No es el último día del mes.\n"
     ]
    }
   ],
   "source": [
    "#TODO: testeando fecha ultimo dia del mes para los corregidos\n",
    "\n",
    "def es_ultimo_dia_del_mes(fecha):\n",
    "    siguiente_mes = fecha.replace(day=28) + timedelta(days=4)  # Pasamos al día 28 y sumamos 4 días\n",
    "    ultimo_dia = siguiente_mes - timedelta(days=siguiente_mes.day)\n",
    "    return fecha.day == ultimo_dia.day\n",
    "\n",
    "# Obtener la fecha actual\n",
    "fecha_now = datetime.now()\n",
    "\n",
    "print(es_ultimo_dia_del_mes())\n",
    "\n",
    "# Verificar si es el último día del mes\n",
    "if es_ultimo_dia_del_mes(fecha_now):\n",
    "    print(\"Es el último día del mes.\")\n",
    "else:\n",
    "    print(\"No es el último día del mes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEMO_CORREGIDOS = \"PARTE_POST_OPERATIVO_UNIF\"\n",
    "NEMO_NO_CORREGIDOS = \"PARTE_POST_OPERATIVO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-31\n",
      "2024-06-12\n"
     ]
    }
   ],
   "source": [
    "print(ultimo_dia(\"Valores_Corregidos_Test\"))\n",
    "print(ultimo_dia_CAMM(\"PARTE_POST_OPERATIVO_UNIF\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS DE LA BBDD, SERVER Y TABLA\n",
    "\n",
    "server = 'DARCCVWSQL19'\n",
    "database = 'TAPI'\n",
    "\n",
    "#1\n",
    "#-------------------------------------------------------#\n",
    "tabla_valores = 'Valores_Corregidos_Test'\n",
    "#tabla_contratos = 'Contratos_Corregidos'\n",
    "#tabla_novedades = 'Novedades_Corregidos'\n",
    "\n",
    "#-------------------------------------------------------#\n",
    "\n",
    "#2\n",
    "#-------------------------------------------------------#\n",
    "# Fechas para seleccionar el día de la carga se debe iterar\n",
    "\n",
    "# fecha_desde_obj = datetime.fromisoformat(ultimo_dia_bd())\n",
    "\n",
    "# fecha_hasta_obj = datetime.fromisoformat(ultimo_dia_CAMM())\n",
    "\n",
    "# fecha_desde_bd = ultimo_dia_bd() #OJO DE QUE TABLA TOMA EL ULTIMO DIA\n",
    "\n",
    "# fecha_datetime = datetime.strptime(fecha_desde_bd, \"%Y-%m-%d\")\n",
    "\n",
    "# fecha_siguiente = fecha_datetime + timedelta(days=1) #Sumar un día\n",
    "\n",
    "# fecha_desde = fecha_siguiente.strftime(\"%Y-%m-%d\") #Convertir de nuevo a string si es necesario\n",
    "\n",
    "# fecha_hasta = ultimo_dia_CAMM() #ultimo informe en API CAMMESA\n",
    "\n",
    "# fecha_desde = fecha_desde+\"T00:00:00.000-03:00\" \n",
    "# fecha_hasta = fecha_hasta+\"T23:59:00.000-03:00\"\n",
    "\n",
    "# fecha_desde_datetime = datetime.strptime(fecha_desde)\n",
    "# fecha_hasta_datetime = datetime.strptime(fecha_hasta)\n",
    "\n",
    "#fecha_desde = \"2024-04-20T00:00:00.000-03:00\"\n",
    "#fecha_hasta = \"2024-04-30T23:59:59.000-03:00\"\n",
    "\n",
    "#Defino la tabla de CAMMESA que me voy a traer\n",
    "\n",
    "NEMO_CORREGIDOS = \"PARTE_POST_OPERATIVO_UNIF\"\n",
    "NEMO_NO_CORREGIDOS = \"PARTE_POST_OPERATIVO\"\n",
    "#-------------------------------------------------------#\n",
    "\n",
    "#URL para capturar Id del documento y el zip file:\n",
    "\n",
    "#Busco los zip disponibles para traer así puedo extraer el id\n",
    "URL = f\"https://api.cammesa.com/pub-svc/public/\"\n",
    "\n",
    "method_id = \"findDocumentosByNemoRango?\" #ID\n",
    "method_zip = \"findAllAttachmentZipByNemoId?\" #metodo\n",
    "\n",
    "\n",
    "zip_path = r\".zips\"\n",
    "mdb_path = r\".zips\\.mdb\"\n",
    "\n",
    "connection_string = f'DRIVER=ODBC Driver 17 for SQL Server;SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "\n",
    "# Establecer la conexión con la base de datos de SQL Server\n",
    "conn = pyodbc.connect(connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#url_doc_id = f\"{URL}{method_id}fechadesde={fecha_desde}&fechahasta={fecha_hasta}&nemo={NEMO}\"\n",
    "\n",
    "dataframes = []\n",
    "dfout = pd.DataFrame()\n",
    "dfout2 = pd.DataFrame()\n",
    "df_filtrado = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_desde = \"2024-05-01T00:00:00.000-03:00\"\n",
    "fecha_hasta = \"2024-05-31T23:59:59.000-03:00\"\n",
    "fecha_desde_obj = 0\n",
    "fecha_hasta_obj = 1\n",
    "\n",
    "fecha_ultimo_dia_mes = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ejecuta el día 2024-06-14 14:03:56.664653\n",
      "Se realiza el update\n",
      "01-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31-05-2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadurian\\AppData\\Local\\Temp\\ipykernel_4204\\1865625304.py:79: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finaliza la carga\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def principal_no_corregidos():\n",
    "\n",
    "    if fecha_desde_obj < fecha_hasta_obj:\n",
    "        print(\"Se realiza el update\")\n",
    "\n",
    "        for fecha_actual, fecha_siguiente in iterar_entre_fechas(fecha_desde, fecha_hasta):\n",
    "            \n",
    "            #inicializo los 3 dataframes del proceso\n",
    "            valores_generadores = pd.DataFrame()\n",
    "            contrato_abastecimiento = pd.DataFrame()\n",
    "            novedades = pd.DataFrame()\n",
    "\n",
    "            #url para obtener el doc id de las fecha de la iteracion\n",
    "            url_doc_id = f\"{URL}{method_id}fechadesde={fecha_actual.isoformat()}&fechahasta={fecha_siguiente.isoformat()}&nemo={NEMO_NO_CORREGIDOS}\"\n",
    "            \n",
    "            #obtener el doc_id del dia actual (corregido)\n",
    "            dia_mdb = fecha_actual.strftime(\"%d-%m-%Y\")\n",
    "            try:\n",
    "                with requests.get(url_doc_id) as response:\n",
    "                    if response.status_code == 200:\n",
    "                        PPO=response.json()\n",
    "                        doc_id = PPO[-1]['id']\n",
    "                        print(dia_mdb)\n",
    "                    else:\n",
    "                        print(\"La solicitud falló con el código de estado:\", response.status_code)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                # Manejar la excepción\n",
    "                print(\"Error al realizar la solicitud:\", e)\n",
    "\n",
    "\n",
    "            #url para generar el .zip del doc id del día de la iteracion\n",
    "            url_zip = f\"{URL}{method_zip}docId={doc_id}&nemo={NEMO_NO_CORREGIDOS}\"\n",
    "\n",
    "\n",
    "            #descargar el .zip del doc_id (corregido)\n",
    "            try:\n",
    "                with requests.get(url_doc_id) as response:\n",
    "                    if response.status_code == 200:\n",
    "                        r = requests.get(url_zip)\n",
    "\n",
    "                        # Crear un objeto ZipFile a partir del contenido descargado\n",
    "                        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "                        # Directorio de destino para extraer los archivos ZIP\n",
    "                        destination_directory = \".zips\"\n",
    "\n",
    "                        # Extraer todos los archivos del ZIP en el directorio específico\n",
    "                        z.extractall(destination_directory)\n",
    "                        zip_name = z.namelist()[0]\n",
    "                    else:\n",
    "                        print(\"La solicitud falló con el código de estado:\", response.status_code)\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                # Manejar la excepción\n",
    "                print(\"Error al realizar la solicitud:\", e)\n",
    "            \n",
    "            #Colocar los PATHs correctos donde se traeran los archivos\n",
    "            \n",
    "            path_zip_dia = f\"{zip_path}\\{zip_name}\"\n",
    "\n",
    "            #display(path_zip_dia)\n",
    "\n",
    "            \n",
    "            try:\n",
    "                # Extrae el archivo MDB de cada archivo ZIP diario\n",
    "                with zipfile.ZipFile(path_zip_dia, 'r') as zip_ref:\n",
    "                    # Encontrar el nombre del archivo MDB dentro del ZIP diario\n",
    "                    archivo_mdb = os.path.splitext(zip_name)[0] + \".mdb\"\n",
    "                    zip_ref.extract(archivo_mdb, path=mdb_path)\n",
    "\n",
    "        \n",
    "                # Lee el archivo MDB y cargar la tabla VALORES_GENERADORES en un dataframe\n",
    "                mdb_file = os.path.join(mdb_path, archivo_mdb)\n",
    "                conn_str = f\"Driver={{Microsoft Access Driver (*.mdb, *.accdb)}};DBQ={mdb_file};\"\n",
    "                conn = pyodbc.connect(conn_str)\n",
    "\n",
    "                #3\n",
    "                #-------------------------------------------------------#\n",
    "                valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n",
    "                #contrato_abastecimiento = pd.read_sql(\"SELECT * FROM CONTRATO_ABASTECIMIENTO\", conn)\n",
    "                #novedades = pd.read_sql(\"SELECT * FROM NOVEDADES\", conn)\n",
    "                #-------------------------------------------------------#\n",
    "                conn.close()\n",
    "                \n",
    "                # Convertir dia_mdb a un objeto datetime\n",
    "                dia_datetime = datetime.strptime(dia_mdb, '%d-%m-%Y')\n",
    "\n",
    "                # Formatear la fecha en el formato YYYY-MM-DD como una cadena\n",
    "                dia_mdb_formatted = dia_datetime.strftime('%Y-%m-%d')\n",
    "\n",
    "                # Insertar la fecha formateada en la lista valores_generadores\n",
    "                \n",
    "                #4\n",
    "                #-------------------------------------------------------#\n",
    "                valores_generadores.insert(0, 'FECHA', dia_mdb_formatted)\n",
    "\n",
    "                #contrato_abastecimiento.insert(0, 'FECHA', dia_mdb_formatted)\n",
    "\n",
    "                #novedades.insert(0, 'FECHA', dia_mdb_formatted)\n",
    "                #-------------------------------------------------------#\n",
    "                quoted = urllib.parse.quote_plus(connection_string)\n",
    "\n",
    "                #Por limitaciones de tamaño de excel filtramos solo las máquinas Pampa\n",
    "                valores_filtrados = [\"ADTOHI\", \"AR21EO\", \"BAHIEO\", \"BBLATV29\", \"BBLATV30\",\n",
    "                                    \"BBLMDI01\", \"BBLMDI02\", \"BBLMDI03\", \"BBLMDI04\", \n",
    "                                    \"BBLMDI05\", \"BBLMDI06\", \"CERITV01\", \"CORTEO\", \n",
    "                                    \"EBARTG01\", \"EBARTG02\", \"EBARTV01\", \"ETIGHI\", \n",
    "                                    \"GEBATG01\", \"GEBATG02\", \"GEBATG03\", \"GEBATG04\", \n",
    "                                    \"GEBATV01\", \"GEBATV02\", \"GUEMTG01\", \"GUEMTV11\", \n",
    "                                    \"GUEMTV12\", \"GUEMTV13\", \"LDLATG01\", \"LDLATG02\", \n",
    "                                    \"LDLATG03\", \"LDLATG04\", \"LDLATG05\", \"LDLATV01\", \n",
    "                                    \"LDLMDI01\", \"LREYHB\", \"NIH1HI\", \"NIH2HI\", \"NIH3HI\", \n",
    "                                    \"PAMEEO\",\"PE32EO\", \"PEP3EO\", \"PILBDI01\", \"PILBDI02\", \n",
    "                                    \"PILBDI03\", \"PILBDI04\", \"PILBDI05\", \"PILBDI06\", \"PIQIDI01\", \"PPLEHI\"]\n",
    "                \n",
    "                contratos_filtrados = [\"C.T. LOMA DE LA LATA\", \"C.T.E.BARRAGAN TV-M\", \"CT LOMA II LA LATA-M\", \"GENELBA CC -MERCA\", \"PIEDRABUENA  R21-\",\"CT PILAR BS AS M\"]\n",
    "\n",
    "                # Filtrar el DataFrame por los valores especificados en la columna \"GRUPO\"\n",
    "\n",
    "                #DEFINIR EL DF A SUBIR\n",
    "\n",
    "                #5\n",
    "                #-------------------------------------------------------#\n",
    "\n",
    "                df_valores = valores_generadores[valores_generadores[\"GRUPO\"].isin(valores_filtrados)]  \n",
    "                \n",
    "                #df_contratos = contrato_abastecimiento[contrato_abastecimiento[\"CONTRATO\"].isin(contratos_filtrados)]\n",
    "\n",
    "                #df_novedades = novedades[novedades[\"GRUPO\"].isin(valores_filtrados)]\n",
    "\n",
    "                #-------------------------------------------------------#\n",
    "\n",
    "                #TODO: Revisar el filtrado previo a igresar la data    \n",
    "                \n",
    "                #df_filtrado = df_filtrado.sort_values(by=['FECHA', 'HORA', 'GRUPO'])\n",
    "\n",
    "                engine = sqlalchemy.create_engine('mssql+pyodbc:///?odbc_connect={}'.format(quoted))\n",
    "            \n",
    "                #ACÁ ESCRIBE LA DATA, REVISAR SIEMPRE ARGUMENTOS\n",
    "\n",
    "                #6\n",
    "                #-------------------------------------------------------#\n",
    "\n",
    "                df_valores.to_sql(f'{tabla_valores}', schema='dbo', con=engine, if_exists='append', chunksize=20000)\n",
    "\n",
    "                #df_contratos.to_sql(f'{tabla_contratos}', schema='dbo', con=engine, if_exists='append', chunksize=20000)\n",
    "\n",
    "                #df_novedades.to_sql(f'{tabla_novedades}', schema='dbo', con=engine, if_exists='append', chunksize=20000)\n",
    "\n",
    "                #dfout = pd.concat([dfout,df_valores], ignore_index=True)\n",
    "                #dfout2 = pd.concat([dfout2, df_contratos], ignore_index=True)\n",
    "\n",
    "                #-------------------------------------------------------#\n",
    "                \n",
    "            except FileNotFoundError:\n",
    "                print(f\"El archivo {zip_name} no se encontró. Saltando al siguiente archivo...\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Última fecha en BD:{fecha_desde_obj} es igual a la última fecha del informe de CAMMESA: {fecha_hasta_obj}\\nNo se realiza el update\")\n",
    "\n",
    "    print(\"Finaliza la carga de No Corregidos\")\n",
    "\n",
    "def principal_corregidos():\n",
    "\n",
    "    if fecha_desde_obj < fecha_hasta_obj:\n",
    "        print(\"Se realiza el update de Corregidos\")\n",
    "\n",
    "        for fecha_actual, fecha_siguiente in iterar_entre_fechas(fecha_desde, fecha_hasta):\n",
    "            \n",
    "            #inicializo los 3 dataframes del proceso\n",
    "            valores_generadores = pd.DataFrame()\n",
    "            contrato_abastecimiento = pd.DataFrame()\n",
    "            novedades = pd.DataFrame()\n",
    "\n",
    "            #url para obtener el doc id de las fecha de la iteracion\n",
    "            url_doc_id = f\"{URL}{method_id}fechadesde={fecha_actual.isoformat()}&fechahasta={fecha_siguiente.isoformat()}&nemo={NEMO_CORREGIDOS}\"\n",
    "            \n",
    "            #obtener el doc_id del dia actual (corregido)\n",
    "            dia_mdb = fecha_actual.strftime(\"%d-%m-%Y\")\n",
    "            try:\n",
    "                with requests.get(url_doc_id) as response:\n",
    "                    if response.status_code == 200:\n",
    "                        PPO=response.json()\n",
    "                        doc_id = PPO[-1]['id']\n",
    "                        print(dia_mdb)\n",
    "                    else:\n",
    "                        print(\"La solicitud falló con el código de estado:\", response.status_code)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                # Manejar la excepción\n",
    "                print(\"Error al realizar la solicitud:\", e)\n",
    "\n",
    "\n",
    "            #url para generar el .zip del doc id del día de la iteracion\n",
    "            url_zip = f\"{URL}{method_zip}docId={doc_id}&nemo={NEMO_CORREGIDOS}\"\n",
    "\n",
    "\n",
    "            #descargar el .zip del doc_id (corregido)\n",
    "            try:\n",
    "                with requests.get(url_doc_id) as response:\n",
    "                    if response.status_code == 200:\n",
    "                        r = requests.get(url_zip)\n",
    "\n",
    "                        # Crear un objeto ZipFile a partir del contenido descargado\n",
    "                        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "                        # Directorio de destino para extraer los archivos ZIP\n",
    "                        destination_directory = \".zips\"\n",
    "\n",
    "                        # Extraer todos los archivos del ZIP en el directorio específico\n",
    "                        z.extractall(destination_directory)\n",
    "                        zip_name = z.namelist()[0]\n",
    "                    else:\n",
    "                        print(\"La solicitud falló con el código de estado:\", response.status_code)\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                # Manejar la excepción\n",
    "                print(\"Error al realizar la solicitud:\", e)\n",
    "            \n",
    "            #Colocar los PATHs correctos donde se traeran los archivos\n",
    "            \n",
    "            path_zip_dia = f\"{zip_path}\\{zip_name}\"\n",
    "\n",
    "            #display(path_zip_dia)\n",
    "\n",
    "            \n",
    "            try:\n",
    "                # Extrae el archivo MDB de cada archivo ZIP diario\n",
    "                with zipfile.ZipFile(path_zip_dia, 'r') as zip_ref:\n",
    "                    # Encontrar el nombre del archivo MDB dentro del ZIP diario\n",
    "                    archivo_mdb = os.path.splitext(zip_name)[0] + \".mdb\"\n",
    "                    zip_ref.extract(archivo_mdb, path=mdb_path)\n",
    "\n",
    "        \n",
    "                # Lee el archivo MDB y cargar la tabla VALORES_GENERADORES en un dataframe\n",
    "                mdb_file = os.path.join(mdb_path, archivo_mdb)\n",
    "                conn_str = f\"Driver={{Microsoft Access Driver (*.mdb, *.accdb)}};DBQ={mdb_file};\"\n",
    "                conn = pyodbc.connect(conn_str)\n",
    "\n",
    "                #3\n",
    "                #-------------------------------------------------------#\n",
    "                valores_generadores = pd.read_sql(\"SELECT * FROM VALORES_GENERADORES\", conn)\n",
    "                #contrato_abastecimiento = pd.read_sql(\"SELECT * FROM CONTRATO_ABASTECIMIENTO\", conn)\n",
    "                #novedades = pd.read_sql(\"SELECT * FROM NOVEDADES\", conn)\n",
    "                #-------------------------------------------------------#\n",
    "                conn.close()\n",
    "                \n",
    "                # Convertir dia_mdb a un objeto datetime\n",
    "                dia_datetime = datetime.strptime(dia_mdb, '%d-%m-%Y')\n",
    "\n",
    "                # Formatear la fecha en el formato YYYY-MM-DD como una cadena\n",
    "                dia_mdb_formatted = dia_datetime.strftime('%Y-%m-%d')\n",
    "\n",
    "                # Insertar la fecha formateada en la lista valores_generadores\n",
    "                \n",
    "                #4\n",
    "                #-------------------------------------------------------#\n",
    "                valores_generadores.insert(0, 'FECHA', dia_mdb_formatted)\n",
    "\n",
    "                #contrato_abastecimiento.insert(0, 'FECHA', dia_mdb_formatted)\n",
    "\n",
    "                #novedades.insert(0, 'FECHA', dia_mdb_formatted)\n",
    "                #-------------------------------------------------------#\n",
    "                quoted = urllib.parse.quote_plus(connection_string)\n",
    "\n",
    "                #Por limitaciones de tamaño de excel filtramos solo las máquinas Pampa\n",
    "                valores_filtrados = [\"ADTOHI\", \"AR21EO\", \"BAHIEO\", \"BBLATV29\", \"BBLATV30\",\n",
    "                                    \"BBLMDI01\", \"BBLMDI02\", \"BBLMDI03\", \"BBLMDI04\", \n",
    "                                    \"BBLMDI05\", \"BBLMDI06\", \"CERITV01\", \"CORTEO\", \n",
    "                                    \"EBARTG01\", \"EBARTG02\", \"EBARTV01\", \"ETIGHI\", \n",
    "                                    \"GEBATG01\", \"GEBATG02\", \"GEBATG03\", \"GEBATG04\", \n",
    "                                    \"GEBATV01\", \"GEBATV02\", \"GUEMTG01\", \"GUEMTV11\", \n",
    "                                    \"GUEMTV12\", \"GUEMTV13\", \"LDLATG01\", \"LDLATG02\", \n",
    "                                    \"LDLATG03\", \"LDLATG04\", \"LDLATG05\", \"LDLATV01\", \n",
    "                                    \"LDLMDI01\", \"LREYHB\", \"NIH1HI\", \"NIH2HI\", \"NIH3HI\", \n",
    "                                    \"PAMEEO\",\"PE32EO\", \"PEP3EO\", \"PILBDI01\", \"PILBDI02\", \n",
    "                                    \"PILBDI03\", \"PILBDI04\", \"PILBDI05\", \"PILBDI06\", \"PIQIDI01\", \"PPLEHI\"]\n",
    "                \n",
    "                contratos_filtrados = [\"C.T. LOMA DE LA LATA\", \"C.T.E.BARRAGAN TV-M\", \"CT LOMA II LA LATA-M\", \"GENELBA CC -MERCA\", \"PIEDRABUENA  R21-\",\"CT PILAR BS AS M\"]\n",
    "\n",
    "                # Filtrar el DataFrame por los valores especificados en la columna \"GRUPO\"\n",
    "\n",
    "                #DEFINIR EL DF A SUBIR\n",
    "\n",
    "                #5\n",
    "                #-------------------------------------------------------#\n",
    "\n",
    "                df_valores = valores_generadores[valores_generadores[\"GRUPO\"].isin(valores_filtrados)]  \n",
    "                \n",
    "                #df_contratos = contrato_abastecimiento[contrato_abastecimiento[\"CONTRATO\"].isin(contratos_filtrados)]\n",
    "\n",
    "                #df_novedades = novedades[novedades[\"GRUPO\"].isin(valores_filtrados)]\n",
    "\n",
    "                #-------------------------------------------------------#\n",
    "\n",
    "                #TODO: Revisar el filtrado previo a igresar la data    \n",
    "                \n",
    "                #df_filtrado = df_filtrado.sort_values(by=['FECHA', 'HORA', 'GRUPO'])\n",
    "\n",
    "                engine = sqlalchemy.create_engine('mssql+pyodbc:///?odbc_connect={}'.format(quoted))\n",
    "            \n",
    "                #ACÁ ESCRIBE LA DATA, REVISAR SIEMPRE ARGUMENTOS\n",
    "\n",
    "                #6\n",
    "                #-------------------------------------------------------#\n",
    "\n",
    "                df_valores.to_sql(f'{tabla_valores}', schema='dbo', con=engine, if_exists='append', chunksize=20000)\n",
    "\n",
    "                #df_contratos.to_sql(f'{tabla_contratos}', schema='dbo', con=engine, if_exists='append', chunksize=20000)\n",
    "\n",
    "                #df_novedades.to_sql(f'{tabla_novedades}', schema='dbo', con=engine, if_exists='append', chunksize=20000)\n",
    "\n",
    "                #dfout = pd.concat([dfout,df_valores], ignore_index=True)\n",
    "                #dfout2 = pd.concat([dfout2, df_contratos], ignore_index=True)\n",
    "\n",
    "                #-------------------------------------------------------#\n",
    "                \n",
    "            except FileNotFoundError:\n",
    "                print(f\"El archivo {zip_name} no se encontró. Saltando al siguiente archivo...\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Última fecha en BD:{fecha_desde_obj} es igual a la última fecha del informe de CAMMESA: {fecha_hasta_obj}\\nNo se realiza el update\")\n",
    "\n",
    "    print(\"Finaliza la carga de Corregidos\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    now = datetime.now()\n",
    "    print(f\"Se ejecuta el día {now}\")\n",
    "    print(f\"Se ejecuta funcion principal_no_corregidos\")\n",
    "    principal_no_corregidos()\n",
    "    print(f\"Se ejecuta funcion principal_corregidos\")\n",
    "    principal_corregidos()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvPampa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
